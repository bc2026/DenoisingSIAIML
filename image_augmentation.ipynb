{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3362,"databundleVersionId":31148,"sourceType":"competition"},{"sourceId":11356725,"sourceType":"datasetVersion","datasetId":7107361},{"sourceId":11547584,"sourceType":"datasetVersion","datasetId":7241660}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport zipfile\nimport shutil\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:01.271848Z","iopub.execute_input":"2025-05-02T16:45:01.272775Z","iopub.status.idle":"2025-05-02T16:45:01.293722Z","shell.execute_reply.started":"2025-05-02T16:45:01.272722Z","shell.execute_reply":"2025-05-02T16:45:01.291470Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dogs-vs-cats/test1.zip\n/kaggle/input/dogs-vs-cats/train.zip\n/kaggle/input/dogs-vs-cats/sampleSubmission.csv\n/kaggle/input/cell1-s1/cp.ipynb.tif\n/kaggle/input/cells1-particle-positions-with-starting-point/CellS1_particle_positions_with_starting_point.csv\n","output_type":"stream"}],"execution_count":154},{"cell_type":"code","source":"path_to_tif = '/kaggle/input/cell1-s1/cp.ipynb.tif'\n\nimage = Image.open(path_to_tif)\nprint(\"Image mode:\", image.mode)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:01.297266Z","iopub.execute_input":"2025-05-02T16:45:01.298004Z","iopub.status.idle":"2025-05-02T16:45:01.346423Z","shell.execute_reply.started":"2025-05-02T16:45:01.297776Z","shell.execute_reply":"2025-05-02T16:45:01.343365Z"}},"outputs":[{"name":"stdout","text":"Image mode: I;16\n","output_type":"stream"}],"execution_count":155},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport pandas as pd\n\n# Load .tif image and normalize frames to [0, 1]\npath_to_tif = '/kaggle/input/cell1-s1/cp.ipynb.tif'\nimage = Image.open(path_to_tif)\n\nframes = []\nfor i in range(image.n_frames):\n    image.seek(i)\n    frame_array = np.array(image).astype(np.float32) / 65535.0  # Normalize to [0, 1]\n    frames.append(frame_array)\n\n# Get image dimensions (assuming all frames have same size)\nimg_height, img_width = frames[0].shape\n\n# Load and normalize keypoints\npath_to_csv = '/kaggle/input/cells1-particle-positions-with-starting-point/CellS1_particle_positions_with_starting_point.csv'\ndf = pd.read_csv(path_to_csv)\n\n# Normalize keypoints to [0, 1]\ndf['x_norm'] = df['centroidGlobalColX'] / img_width\ndf['y_norm'] = df['centroidGlobalRowY'] / img_height\n\n# Create list of normalized keypoints\nkeypoints = list(zip(df['x_norm'], df['y_norm']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:01.350413Z","iopub.execute_input":"2025-05-02T16:45:01.350933Z","iopub.status.idle":"2025-05-02T16:45:06.716426Z","shell.execute_reply.started":"2025-05-02T16:45:01.350885Z","shell.execute_reply":"2025-05-02T16:45:06.711383Z"}},"outputs":[],"execution_count":156},{"cell_type":"code","source":"IMG_SIZE = img_width if img_width==img_height else -1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:06.721622Z","iopub.execute_input":"2025-05-02T16:45:06.722075Z","iopub.status.idle":"2025-05-02T16:45:06.733239Z","shell.execute_reply.started":"2025-05-02T16:45:06.722043Z","shell.execute_reply":"2025-05-02T16:45:06.728779Z"}},"outputs":[],"execution_count":157},{"cell_type":"code","source":"transform = A.Compose([\n    A.Rotate(limit=40, p=1.0),\n    A.HorizontalFlip(p=1.0),\n    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=0, p=1.0),\n    A.RandomBrightnessContrast(p=0.5)\n], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:06.735954Z","iopub.execute_input":"2025-05-02T16:45:06.737190Z","iopub.status.idle":"2025-05-02T16:45:06.774450Z","shell.execute_reply.started":"2025-05-02T16:45:06.736937Z","shell.execute_reply":"2025-05-02T16:45:06.771359Z"}},"outputs":[],"execution_count":158},{"cell_type":"code","source":"def make_batches(images, keypoints, batch_size):\n    total = len(images)\n    num_batches = math.ceil(total / batch_size)\n\n    batches = []\n    for i in range(num_batches):\n        start = i * batch_size\n        end = start + batch_size\n        batch_images = images[start:end]\n        batch_keypoints = keypoints[start:end]\n        batches.append((batch_images, batch_keypoints))\n    return batches\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:06.775841Z","iopub.execute_input":"2025-05-02T16:45:06.776754Z","iopub.status.idle":"2025-05-02T16:45:06.813982Z","shell.execute_reply.started":"2025-05-02T16:45:06.776665Z","shell.execute_reply":"2025-05-02T16:45:06.812562Z"}},"outputs":[],"execution_count":159},{"cell_type":"code","source":"batch_size = 32\naugmented_batches = {}\n\nbatches = make_batches(images=frames, keypoints=keypoints, batch_size=batch_size)\n# Make a |frames| x N set of data\n# All identical right now\n# Shape: [[array(img), keypoints], ... ]\n    #                               ^\n    #                            batch Entries\nlen(batches)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:06.815209Z","iopub.execute_input":"2025-05-02T16:45:06.815752Z","iopub.status.idle":"2025-05-02T16:45:06.859729Z","shell.execute_reply.started":"2025-05-02T16:45:06.815707Z","shell.execute_reply":"2025-05-02T16:45:06.857647Z"}},"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}],"execution_count":160},{"cell_type":"code","source":"for index, (bimg_batch, bkp_batch) in enumerate(batches):\n    augmented_images = []\n    augmented_keypoints = []\n\n    for bimg, bkp in zip(bimg_batch, bkp_batch):\n        # If bkp is a single keypoint (x, y), wrap it\n        augmented = transform(image=bimg, keypoints=[bkp])\n    \n\n        \n        augmented_images.append(np.divide(augmented['image'],IMG_SIZE))\n        augmented_keypoints.append(np.divide(augmented['keypoints'], IMG_SIZE))  # Unwrap single keypoint\n\n        \n\n    augmented_batches[index] = (augmented_images, augmented_keypoints)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:06.863827Z","iopub.execute_input":"2025-05-02T16:45:06.864889Z","iopub.status.idle":"2025-05-02T16:45:18.979409Z","shell.execute_reply.started":"2025-05-02T16:45:06.864761Z","shell.execute_reply":"2025-05-02T16:45:18.977941Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"for index, (images, keypoints) in augmented_batches.items():\n    np.savez(f'./augs/batch_{index}.npz', images=np.array(images, dtype=object), keypoints=np.array(keypoints, dtype=object))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:45:18.980886Z","iopub.execute_input":"2025-05-02T16:45:18.981410Z","iopub.status.idle":"2025-05-02T16:46:17.158150Z","shell.execute_reply.started":"2025-05-02T16:45:18.981334Z","shell.execute_reply":"2025-05-02T16:46:17.156162Z"}},"outputs":[],"execution_count":162},{"cell_type":"code","source":"import zipfile\nimport glob\n\nzip_path = \"/kaggle/working/Augmentations.zip\"\nnpz_files = glob.glob(\"/kaggle/working/augs/*.npz\")\n\nwith zipfile.ZipFile(zip_path, 'w') as zipf:\n    for file in npz_files:\n        zipf.write(file, arcname=file.split('/')[-1])  # saves only the filename in the archive\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:46:17.160212Z","iopub.execute_input":"2025-05-02T16:46:17.160624Z","iopub.status.idle":"2025-05-02T16:46:31.935347Z","shell.execute_reply.started":"2025-05-02T16:46:17.160570Z","shell.execute_reply":"2025-05-02T16:46:31.933719Z"}},"outputs":[],"execution_count":163}]}